{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25849\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "import numpy as np\n",
    "import sys,os\n",
    "import glob\n",
    "from math import log10\n",
    "from nltk.corpus import wordnet as wn\n",
    "import string\n",
    "from sklearn import feature_extraction\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stopwords=[line.strip() for line in open('stopwords','r').readlines()]\n",
    "\n",
    "def labelmax(p):\n",
    "    max_prob=0\n",
    "    for label,prob in p.items():\n",
    "        if max_prob<prob:\n",
    "            prob=max_prob\n",
    "            max_label=label\n",
    "    return max_label\n",
    "\n",
    "def clean(sent):\n",
    "    delstr='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t'\n",
    "    identify = string.maketrans(delstr,' '*len(delstr))\n",
    "    return sent.translate(identify)\n",
    "    # return sents\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        import unicodedata\n",
    "        unicodedata.numeric(s)\n",
    "        return True\n",
    "    except (TypeError, ValueError):\n",
    "        pass\n",
    "    return False\n",
    "\n",
    "def stem(word):\n",
    "    try:\n",
    "        res=wn.morphy(word)\n",
    "    except:\n",
    "        res=''\n",
    "    if res!=None and res not in stopwords and not is_number(res):\n",
    "        return res.encode('ascii')\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "\n",
    "def count(docs,word):\n",
    "    total=0\n",
    "    for doc in docs:\n",
    "        total+=doc.count(word)\n",
    "    return total\n",
    "root='20_newsgroups'\n",
    "train_set={}\n",
    "test_set={}\n",
    "text_labels=[]\n",
    "text_count=[]\n",
    "newdir='all'\n",
    "for filedir in glob.glob(os.path.join(root, '*')):\n",
    "    #text labels and sizes\n",
    "    label = filedir.split('/')[-1]\n",
    "    text_labels.append(label)\n",
    "    files=glob.glob(os.path.join(filedir, '*'))\n",
    "    size=len(files)\n",
    "    text_count.append(size)\n",
    "\n",
    "    #departure of train and test sets\n",
    "    train_set[label]=[]\n",
    "    test_set[label]=[]\n",
    "    indices = np.random.permutation(size)\n",
    "    for i in indices[:int(size*0.8)]:\n",
    "        lines=open(files[i],'r').readlines()\n",
    "        for i,line in enumerate(lines):\n",
    "            if line.startswith('Lines'):\n",
    "                ind=i\n",
    "                break\n",
    "        seq = [stem(word) for word in ' '.join([clean(line.strip().lower()) for line in lines[ind+1:]]).strip().split() if stem(word)!='']\n",
    "        # print seq\n",
    "        train_set[label].append(seq)\n",
    "    for i in indices[int(size*0.8):]:\n",
    "        lines=open(files[i],'r').readlines()\n",
    "        for i,line in enumerate(lines):\n",
    "            if line.startswith('Lines'):\n",
    "                ind=i\n",
    "                break\n",
    "        seq = [stem(word) for word in ' '.join([clean(line.strip().lower()) for line in lines[ind+1:]]).strip().split() if stem(word)!='']\n",
    "        # print seq\n",
    "        test_set[label].append(seq)\n",
    "\n",
    "word_bank=set()\n",
    "for doc in train_set.values():\n",
    "    for words in doc:\n",
    "        word_bank|=set(words)\n",
    "print len(word_bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sci.crypt', 'comp.sys.mac.hardware', 'talk.politics.misc', 'soc.religion.christian', 'rec.motorcycles', 'sci.med', 'comp.graphics', 'comp.windows.x', 'comp.sys.ibm.pc.hardware', 'talk.politics.guns', 'alt.atheism', 'comp.os.ms-windows.misc', 'sci.space', 'talk.religion.misc', 'misc.forsale', 'rec.sport.hockey', 'rec.sport.baseball', 'talk.politics.mideast', 'rec.autos', 'sci.electronics']\n",
      "19997\n"
     ]
    }
   ],
   "source": [
    "labels=train_set.keys()\n",
    "print labels\n",
    "corpus=[]\n",
    "label_inds=[]\n",
    "for label,docs in train_set.items():\n",
    "    for doc in docs:\n",
    "        label_inds.append(labels.index(label))\n",
    "        corpus.append(' '.join(doc))\n",
    "for label,docs in test_set.items():\n",
    "    for doc in docs:\n",
    "        label_inds.append(label)\n",
    "        corpus.append(' '.join(doc))\n",
    "print len(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27067\n",
      "(19997, 27067)\n",
      "(19997,)\n"
     ]
    }
   ],
   "source": [
    "label_inds=np.array(label_inds)\n",
    "vectorizer = CountVectorizer()\n",
    "tfidf = TfidfTransformer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print len(vectorizer.get_feature_names())\n",
    "transformer =  TfidfTransformer()  \n",
    "tfidf = transformer.fit_transform(X)  \n",
    "print tfidf.toarray().shape\n",
    "print label_inds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7998, 27067)\n",
      "(6420, 27067) (1578,)\n"
     ]
    }
   ],
   "source": [
    "XX = tfidf.toarray()[:int(len(corpus)*0.4)]\n",
    "label_inds = label_inds[:int(len(corpus)*0.4)]\n",
    "print XX.shape\n",
    "test_split_mask = np.random.rand(len(XX)) < 0.8\n",
    "train_X = XX[test_split_mask]\n",
    "train_Y = label_inds[test_split_mask]\n",
    "test_X = XX[~test_split_mask]\n",
    "test_Y = label_inds[~test_split_mask]\n",
    "print train_X.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=1)\n",
    "clf.fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.63371356147021551"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_X,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "print clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf=SVC()\n",
    "clf.fit(train_X,train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
